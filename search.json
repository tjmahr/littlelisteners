[{"path":"http://www.tjmahr.com/littlelisteners/articles/aggregating.html","id":"response-definitions","dir":"Articles","previous_headings":"","what":"Response definitions","title":"Aggregating Eyetracking Data","text":"deal eyetracking data generic way, need way describe eyetracking responses. assume four basic gaze types. Primary responses: gaze primary target image. responses: Gazes competing images. Elsewhere looks: gaze onscreen primary response. Typically, occurs participant shifting images. Missing looks: missing offscreen gaze. response definition programmatic way describing response types. code , response_def response definition four-image experiment \"Target\" image three competing images lumped together \"Others\", looks either \"tracked\" missing (NA).","code":"response_def <- create_response_def(   primary = \"Target\",   others = c(\"PhonologicalFoil\", \"SemanticFoil\", \"Unrelated\"),   elsewhere = \"tracked\",   missing = NA,   label = \"looks to target\" ) response_def #> List of 5 #>  $ response_def: chr \"looks to target\" #>  $ primary     : chr \"Target\" #>  $ others      : chr [1:3] \"PhonologicalFoil\" \"SemanticFoil\" \"Unrelated\" #>  $ elsewhere   : chr \"tracked\" #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\""},{"path":"http://www.tjmahr.com/littlelisteners/articles/aggregating.html","id":"aggregating-looks","dir":"Articles","previous_headings":"","what":"Aggregating looks","title":"Aggregating Eyetracking Data","text":"response definitions allow us aggregate looking data generic way. function aggregate_looks() counts number looks four response categories using aggregation formula. example, can count looks participant. several columns , use glimpse() look values every column. looks participant trial. just print dataframe . can also perform kind aggregations using different response definitions. instance, can compare image locations writing new response definition. can perform multiple aggregations . First, cycle_response_def() can create set response definitions response acts primary outcome. given list response definitions, aggregate_looks() right thing computes aggregation one.","code":"four_image_data |>    aggregate_looks(response_def, Subject ~ GazeByImageAOI) |>    glimpse() #> Rows: 1 #> Columns: 14 #> $ .response_def    <chr> \"looks to target\" #> $ Subject          <chr> \"001P\" #> $ PhonologicalFoil <int> 2461 #> $ SemanticFoil     <int> 2478 #> $ Target           <int> 4094 #> $ Unrelated        <int> 2033 #> $ Elsewhere        <dbl> 1202 #> $ Missing          <dbl> 8642 #> $ Others           <dbl> 6972 #> $ Primary          <dbl> 4094 #> $ Looks            <dbl> 20910 #> $ Prop             <dbl> 0.369962 #> $ PropSE           <dbl> 0.004589513 #> $ PropNA           <dbl> 0.4132951 four_image_data |>    aggregate_looks(response_def, Subject + TrialNo ~ GazeByImageAOI) #> # A tibble: 24 × 15 #>    .response_def  Subject TrialNo PhonologicalFoil SemanticFoil Target Unrelated #>    <chr>          <chr>     <int>            <int>        <int>  <int>     <int> #>  1 looks to targ… 001P          1              232           80    250       105 #>  2 looks to targ… 001P          2              181           93    242       160 #>  3 looks to targ… 001P          3               79          101    231        66 #>  4 looks to targ… 001P          4              188          135    123       145 #>  5 looks to targ… 001P          5               90          170    164        79 #>  6 looks to targ… 001P          6               70          198    172        24 #>  7 looks to targ… 001P          7               83           47    109       195 #>  8 looks to targ… 001P          8               60           63     77        40 #>  9 looks to targ… 001P          9               71           50     50        50 #> 10 looks to targ… 001P         10               57          305    150        82 #> # ℹ 14 more rows #> # ℹ 8 more variables: Elsewhere <dbl>, Missing <dbl>, Others <dbl>, #> #   Primary <dbl>, Looks <dbl>, Prop <dbl>, PropSE <dbl>, PropNA <dbl> location_def <- create_response_def(   primary = \"LowerLeftImage\",   others = c(\"UpperRightImage\", \"UpperLeftImage\", \"LowerRightImage\"),   elsewhere = \"tracked\",   missing = NA )  aggregate_looks(four_image_data, location_def, Subject ~ GazeByAOI) |>    glimpse() #> Rows: 1 #> Columns: 14 #> $ .response_def   <chr> \"LowerLeftImage\" #> $ Subject         <chr> \"001P\" #> $ LowerLeftImage  <int> 2761 #> $ LowerRightImage <int> 3099 #> $ UpperLeftImage  <int> 2569 #> $ UpperRightImage <int> 2637 #> $ Elsewhere       <dbl> 1202 #> $ Missing         <dbl> 8642 #> $ Others          <dbl> 8305 #> $ Primary         <dbl> 2761 #> $ Looks           <dbl> 20910 #> $ Prop            <dbl> 0.249503 #> $ PropSE          <dbl> 0.004113552 #> $ PropNA          <dbl> 0.4132951 all_defs <- cycle_response_def(response_def) all_defs #> [[1]] #> List of 5 #>  $ response_def: chr \"Target\" #>  $ primary     : chr \"Target\" #>  $ others      : chr [1:3] \"PhonologicalFoil\" \"SemanticFoil\" \"Unrelated\" #>  $ elsewhere   : chr \"tracked\" #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\" #>  #> [[2]] #> List of 5 #>  $ response_def: chr \"PhonologicalFoil\" #>  $ primary     : chr \"PhonologicalFoil\" #>  $ others      : chr [1:3] \"Target\" \"SemanticFoil\" \"Unrelated\" #>  $ elsewhere   : chr \"tracked\" #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\" #>  #> [[3]] #> List of 5 #>  $ response_def: chr \"SemanticFoil\" #>  $ primary     : chr \"SemanticFoil\" #>  $ others      : chr [1:3] \"Target\" \"PhonologicalFoil\" \"Unrelated\" #>  $ elsewhere   : chr \"tracked\" #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\" #>  #> [[4]] #> List of 5 #>  $ response_def: chr \"Unrelated\" #>  $ primary     : chr \"Unrelated\" #>  $ others      : chr [1:3] \"Target\" \"PhonologicalFoil\" \"SemanticFoil\" #>  $ elsewhere   : chr \"tracked\" #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\" four_image_data |>    aggregate_looks(all_defs, Subject ~ GazeByImageAOI) |>    select(     ResponseDef = .response_def,      Subject, Primary,      Others, Prop, PropSE, PropNA   ) |>    knitr::kable()"},{"path":"http://www.tjmahr.com/littlelisteners/articles/aggregating.html","id":"growth-curve-analysis-is-aggregating-looks-over-time","dir":"Articles","previous_headings":"","what":"Growth curve analysis is aggregating looks over time","title":"Aggregating Eyetracking Data","text":"aggregate_looks(), can estimate growth curves looking probabilities. First, dataset, need adjust eyetracking timestamps time 0 occurs target onset. also going bin downsample eyetracking data effective sampling rate 10 frames per second—just plotting. now four growth curves, one image type, single dataframe. can plot growth curves.","code":"growth_curves <- four_image_data |>    adjust_times(Time, TargetOnset, Subject, BlockNo, TrialNo) |>    filter(-1005 <= Time, Time <= 2000) |>    assign_bins(6, Time, Subject, BlockNo, TrialNo) |>    # Set a time for each bin   group_by(Subject, BlockNo, TrialNo, .bin) |>    mutate(BinTime = round(min(Time))) |>    aggregate_looks(all_defs, Subject + BinTime ~ GazeByImageAOI) |>    rename(Time = BinTime) growth_curves #> # A tibble: 120 × 15 #>    .response_def Subject  Time PhonologicalFoil SemanticFoil Target Unrelated #>    <chr>         <chr>   <dbl>            <int>        <int>  <int>     <int> #>  1 Target        001P    -1000               54           15     52        24 #>  2 Target        001P     -900               48           38     47        33 #>  3 Target        001P     -800               46           45     44        37 #>  4 Target        001P     -700               36           34     53        41 #>  5 Target        001P     -600               38           36     58        43 #>  6 Target        001P     -500               53           30     54        35 #>  7 Target        001P     -400               57           28     38        37 #>  8 Target        001P     -300               67           35     22        32 #>  9 Target        001P     -200               56           55      7        31 #> 10 Target        001P     -100               52           58      9        34 #> # ℹ 110 more rows #> # ℹ 8 more variables: Elsewhere <dbl>, Missing <dbl>, Others <dbl>, #> #   Primary <dbl>, Looks <dbl>, Prop <dbl>, PropSE <dbl>, PropNA <dbl> library(ggplot2) ggplot(growth_curves) +   aes(x = Time, y = Prop, color = .response_def) +   geom_hline(size = 2, color = \"white\", yintercept = .25) +   geom_vline(size = 2, color = \"white\", xintercept = 0) +   geom_pointrange(aes(ymin = Prop - PropSE, ymax = Prop + PropSE)) +   labs(     x = \"Time relative to target onset [ms]\",     y = \"Proportion of looks\",     color = \"Image\"   ) #> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. #> ℹ Please use `linewidth` instead. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated."},{"path":"http://www.tjmahr.com/littlelisteners/articles/tobii-example.html","id":"reading-in-data","dir":"Articles","previous_headings":"","what":"Reading in data","title":"Tobii eyetracking data from scratch","text":"experiment two-image looking--listening design. yaml file includes locations experiment’s areas interest (AOIs) names pertinent fields pull Eprime file. yaml file useful prevents numbers. Eprime file format headache, made rprime package help clean wrangle . first R package function names kind clunky. lot information. can get core experiment’s trial data: Finally, actual eyetracking data. read_gazedata() reads .gazedata file R tibble, applies adjustments based Tobii’s validity coding system, blanks invalid gaze locations, flips y measurements origin lower-left corner screen, computes monocular means eyetracking measurements. Note gaze locations written terms screen proportions, pixels 0 bottom left edge 1 top right edge.","code":"data_yaml <- yaml::read_yaml(paths_to_block1[3]) str(data_yaml) #> List of 5 #>  $ task     : chr \"Coartic\" #>  $ notes    : chr \"Coartic_WFFArea_2a (March 2013--ongoing).\\nThe updated coarticulation pilot experiment incorporated \\\"filler\\\" \"| __truncated__ #>  $ display  :List of 5 #>   ..$ type          : chr \"Tobii60XL\" #>   ..$ frames_per_sec: num 60 #>   ..$ width_pix     : int 1920 #>   ..$ height_pix    : int 1200 #>   ..$ pixels_per_mm : num 3.71 #>  $ aois     :List of 3 #>   ..$ comment: chr \"Describes the location of the onscreen areas of interest (AOIs) with respect to the screen origin. The AOIs are\"| __truncated__ #>   ..$ ImageL :List of 8 #>   .. ..$ name    : chr \"ImageL\" #>   .. ..$ x_length: int 600 #>   .. ..$ y_length: int 600 #>   .. ..$ x_limits: int [1:2] 100 700 #>   .. ..$ y_limits: int [1:2] 300 900 #>   .. ..$ x_origin: chr \"left\" #>   .. ..$ y_origin: chr \"bottom\" #>   .. ..$ units   : chr \"pixels\" #>   ..$ ImageR :List of 8 #>   .. ..$ name    : chr \"ImageR\" #>   .. ..$ x_length: int 600 #>   .. ..$ y_length: int 600 #>   .. ..$ x_limits: int [1:2] 1220 1820 #>   .. ..$ y_limits: int [1:2] 300 900 #>   .. ..$ x_origin: chr \"left\" #>   .. ..$ y_origin: chr \"bottom\" #>   .. ..$ units   : chr \"pixels\" #>  $ locations:List of 2 #>   ..$ comment: chr \"Names of the Eprime columns that say where each image is\" #>   ..$ target : chr \"TargetImage\"  data_yaml$notes |>    strwrap(70) |>    writeLines() #> Coartic_WFFArea_2a (March 2013--ongoing). The updated coarticulation #> pilot experiment incorporated \"filler\" trials and varied Pitch in the #> carrier phrase. There is just one AudioStim file (2190 ms), with the #> following parts: 1. Carrier word (find): 780 ms, 2. the: 560 ms, 3. #> Target (ball): 850 ms. Target-onset occurs 1340 ms after #> AudioStim.OnsetTime. # install.packages(\"rprime\") data_trial_all <- rprime::read_eprime(paths_to_block1[2]) |>    rprime::FrameList() |>    rprime::filter_in(\"Eprime.Level\", 3) |>    rprime::to_data_frame() |>    tibble::as_tibble() data_trial_all #> # A tibble: 24 × 34 #>    Eprime.Level Eprime.LevelName Eprime.Basename    Eprime.FrameNumber Procedure #>           <dbl> <chr>            <chr>              <chr>              <chr>     #>  1            3 TrialList_1      Coartic_Block2_00… 2                  TrialPro… #>  2            3 TrialList_2      Coartic_Block2_00… 3                  TrialPro… #>  3            3 TrialList_3      Coartic_Block2_00… 4                  TrialPro… #>  4            3 TrialList_4      Coartic_Block2_00… 5                  TrialPro… #>  5            3 TrialList_5      Coartic_Block2_00… 6                  TrialPro… #>  6            3 TrialList_6      Coartic_Block2_00… 7                  TrialPro… #>  7            3 TrialList_7      Coartic_Block2_00… 9                  TrialPro… #>  8            3 TrialList_8      Coartic_Block2_00… 10                 TrialPro… #>  9            3 TrialList_9      Coartic_Block2_00… 11                 TrialPro… #> 10            3 TrialList_10     Coartic_Block2_00… 12                 TrialPro… #> # ℹ 14 more rows #> # ℹ 29 more variables: Running <chr>, ImageL <chr>, ImageR <chr>, #> #   Carrier <chr>, Target <chr>, Pitch <chr>, AudioStim <chr>, Attention <chr>, #> #   AudioDur <chr>, AttentionDur <chr>, WordGroup <chr>, StimType <chr>, #> #   TargetWord <chr>, Cycle <chr>, Sample <chr>, Image2sec.OnsetTime <chr>, #> #   Image2sec.StartTime <chr>, Fixation.OnsetDelay <chr>, #> #   Fixation.OnsetTime <chr>, Fixation.StartTime <chr>, … data_trial <- data_trial_all |>    rename_with(     function(x) stringr::str_replace(x, \".OnsetTime\", \"Onset\")   ) |>    rename(CarrierOnset = TargetOnset) |>    mutate(     across(c(ends_with(\"Onset\"), AudioDur), as.numeric),     TargetOnset = as.numeric(CarrierOnset) + 1340,     TrialNo = Eprime.LevelName |>        stringr::str_extract(\"\\\\d+$\") |>        as.numeric()   ) |>    select(     Basename = Eprime.Basename,     TrialNo,     Condition = StimType,     WordGroup,     TargetWord,      Target,     AudioDur,     Image2secOnset,      FixationOnset,      CarrierOnset,      TargetOnset,      Wait1SecFirstOnset,      AttentionOnset   )  data_trial |>    glimpse() #> Rows: 24 #> Columns: 13 #> $ Basename           <chr> \"Coartic_Block2_001P00XS1\", \"Coartic_Block2_001P00X… #> $ TrialNo            <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … #> $ Condition          <chr> \"neutral\", \"competing\", \"filler\", \"neutral\", \"facil… #> $ WordGroup          <chr> \"dog-book\", \"duck-ball\", \"cookie-shoe\", \"dog-book\",… #> $ TargetWord         <chr> \"book\", \"duck\", \"cookie\", \"dog\", \"ball\", \"book\", \"c… #> $ Target             <chr> \"ImageL\", \"ImageR\", \"ImageL\", \"ImageR\", \"ImageR\", \"… #> $ AudioDur           <dbl> 2190, 2190, 2190, 2190, 2190, 2190, 2190, 2190, 219… #> $ Image2secOnset     <dbl> 32797, 41675, 60902, 70750, 80079, 91799, 105526, 1… #> $ FixationOnset      <dbl> 34352, 43230, 62457, 72304, 81651, 93354, 107081, 1… #> $ CarrierOnset       <dbl> 35087, 53412, 63560, 72940, 84426, 93856, 107565, 1… #> $ TargetOnset        <dbl> 36427, 54752, 64900, 74280, 85766, 95196, 108905, 1… #> $ Wait1SecFirstOnset <dbl> 37277, 55602, 65750, 75130, 86616, 96046, 109756, 1… #> $ AttentionOnset     <dbl> 38281, 56605, 66754, 76133, 87619, 97049, 110759, 1… data <- read_gazedata(paths_to_block1[1]) glimpse(data) #> Rows: 15,265 #> Columns: 17 #> $ Basename      <chr> \"Coartic_Block2_001P00XS1\", \"Coartic_Block2_001P00XS1\", … #> $ TrialNo       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… #> $ TobiiTime     <dbl> 1.360681e+12, 1.360681e+12, 1.360681e+12, 1.360681e+12, … #> $ Time          <int> 32789, 32805, 32821, 32840, 32853, 32875, 32905, 32905, … #> $ Origin        <chr> \"LowerLeft\", \"LowerLeft\", \"LowerLeft\", \"LowerLeft\", \"Low… #> $ XLeft         <dbl> 0.3590417, 0.3615159, 0.3729760, 0.3781238, 0.3811296, N… #> $ XRight        <dbl> 0.3945794, 0.3814535, 0.3910438, 0.3896946, 0.3774196, N… #> $ XMean         <dbl> 0.3768106, 0.3714847, 0.3820099, 0.3839092, 0.3792746, N… #> $ YLeft         <dbl> 0.2779693, 0.2805615, 0.2833572, 0.2859311, 0.3208762, N… #> $ YRight        <dbl> 0.2553138, 0.2349956, 0.2570407, 0.2132781, 0.2432799, N… #> $ YMean         <dbl> 0.2666416, 0.2577785, 0.2701989, 0.2496046, 0.2820780, N… #> $ ZLeft         <dbl> 542.9340, 542.9340, 543.7443, 543.7443, 544.3433, NA, NA… #> $ ZRight        <dbl> 528.3995, 528.2514, 528.1776, 528.1776, 528.0162, NA, NA… #> $ ZMean         <dbl> 535.6667, 535.5927, 535.9609, 535.9609, 536.1798, NA, NA… #> $ DiameterLeft  <dbl> 3.846870, 3.638104, 3.692146, 3.343456, 3.469087, NA, NA… #> $ DiameterRight <dbl> 3.627839, 3.651085, 3.590531, 3.453871, 3.542747, NA, NA… #> $ DiameterMean  <dbl> 3.737354, 3.644595, 3.641338, 3.398664, 3.505917, NA, NA…"},{"path":"http://www.tjmahr.com/littlelisteners/articles/tobii-example.html","id":"combining-looking-data-and-trial-data","dir":"Articles","previous_headings":"","what":"Combining looking data and trial data","title":"Tobii eyetracking data from scratch","text":"Basename TrialNo columns allow us combine two dataframes. Now, flurry things. First, define areas interest map looks AOIs. add_aois() maps screen proportions AOI locations. function use work. assumes looks stored XMean YMean columns creates GazeByAOI column. marks onscreen look outside AOI \"tracked\".  can interpolate missing looks remove blinks short gaps data. just fill response_col values gaze locations. recovered: Now map left/right image locations GazeByAOI experimental roles images GazeByImageAOI trial. least clever way table join. final step preprocessing align trials time = 0 target onset. function just work grouped dataframe sigh instead including haphazardly.","code":"data <- data |>    left_join(data_trial, by = c(\"Basename\", \"TrialNo\")) aois <- list(   create_aoi(     aoi_name = data_yaml$aois$ImageL$name,     x_pix = data_yaml$aois$ImageL$x_limits,      y_pix = data_yaml$aois$ImageL$y_limits,     screen_width = data_yaml$display$width_pix,     screen_height = data_yaml$display$height_pix   ),   create_aoi(     aoi_name = data_yaml$aois$ImageR$name,     x_pix = data_yaml$aois$ImageR$x_limits,      y_pix = data_yaml$aois$ImageR$y_limits,     screen_width = data_yaml$display$width_pix,     screen_height = data_yaml$display$height_pix   ) ) data <- data |>    add_aois(aois = aois, default_onscreen = \"tracked\")  ggplot(data) +    aes(x = XMean, y = YMean) +    geom_point(aes(color = GazeByAOI)) +   coord_fixed(1200 / 1920) #> Warning: Removed 11145 rows containing missing values or values outside the scale range #> (`geom_point()`). data <- data |>    group_by(Basename, TrialNo) |>    interpolate_looks(     window = 150,      fps = 60,      response_col = \"GazeByAOI\",      interp_col = \"WasInterpolated\",      fillable = c(\"ImageL\", \"ImageR\"),      missing_looks = NA   ) |>    ungroup() data |>    count(GazeByAOI, WasInterpolated) #> # A tibble: 6 × 3 #>   GazeByAOI WasInterpolated     n #>   <chr>     <lgl>           <int> #> 1 ImageL    FALSE            2739 #> 2 ImageL    TRUE              458 #> 3 ImageR    FALSE             927 #> 4 ImageR    TRUE              172 #> 5 tracked   FALSE             454 #> 6 NA        FALSE           10515 aoi_mapping <- tibble::tribble(   ~GazeByAOI, ~Target, ~GazeByImageAOI,   \"ImageL\",  \"ImageL\", \"Target\",   \"ImageL\",  \"ImageR\", \"Distractor\",   \"ImageR\",  \"ImageR\", \"Target\",   \"ImageR\",  \"ImageL\", \"Distractor\",   \"tracked\", \"ImageL\", \"tracked\",   \"tracked\", \"ImageR\", \"tracked\",   NA,  \"ImageL\", NA,   NA, \"ImageR\", NA )  data <- data |>    left_join(aoi_mapping, by = c(\"Target\", \"GazeByAOI\")) data <- data |>    adjust_times(     time_var = Time, event_var = TargetOnset,      # grouping variables     Basename, TrialNo   )"},{"path":"http://www.tjmahr.com/littlelisteners/articles/tobii-example.html","id":"aggregating-data","dir":"Articles","previous_headings":"","what":"Aggregating data","title":"Tobii eyetracking data from scratch","text":"frame, can count proportion looks target. First, need create response definition tells little listeners treat labels terms targets competitors.  , might combine multiple blocks trials participant together downsample data 50 ms get less jumpy line.","code":"def <- create_response_def(   primary = \"Target\",    others = \"Distractor\",    elsewhere = \"tracked\" )  data_agg <- data |>    filter(-2000 < Time, Time < 2000) |>    aggregate_looks(def, Condition + Time ~ GazeByImageAOI)  ggplot(data_agg) +    aes(x = Time, y = Prop) +   geom_line(aes(color = Condition))"},{"path":"http://www.tjmahr.com/littlelisteners/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tristan Mahr. Author, maintainer.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Mahr T (2024). littlelisteners: Helper Functions Hand-coded Eyetracking Data. R package version 0.0.0.9000, http://www.tjmahr.com/littlelisteners/.","code":"@Manual{,   title = {littlelisteners: Helper Functions for Hand-coded Eyetracking Data},   author = {Tristan Mahr},   year = {2024},   note = {R package version 0.0.0.9000},   url = {http://www.tjmahr.com/littlelisteners/}, }"},{"path":"http://www.tjmahr.com/littlelisteners/index.html","id":"little-listeners","dir":"","previous_headings":"","what":"Helper Functions for Hand-coded Eyetracking Data","title":"Helper Functions for Hand-coded Eyetracking Data","text":"Tools working data word recognition eyetracking experiments.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Helper Functions for Hand-coded Eyetracking Data","text":"First install devtools package, install package repository.","code":"install.packages(\"devtools\") devtools::install_github(\"tjmahr/littlelisteners\")"},{"path":"http://www.tjmahr.com/littlelisteners/index.html","id":"background","dir":"","previous_headings":"","what":"Background","title":"Helper Functions for Hand-coded Eyetracking Data","text":"package developed support eyetracking word recognition experiments Little Listeners project. experiments, images placed onscreen followed spoken prompt view one images. record participant’s gaze location course trial. aggregating gaze location many trials, can describe measure participant’s word recognition showing gaze location changes response speech. littlelisteners (Tristan Mahr’s) second third attempt making eyetracking processing package R. design goals generic (work dataframes eyetracking data) just bespoke outputs individual eyetrackers experiments. package’s code tries play well tidyverse well.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/add_aois.html","id":null,"dir":"Reference","previous_headings":"","what":"Map the x and y positions of looks to Areas of Interest. — add_aois","title":"Map the x and y positions of looks to Areas of Interest. — add_aois","text":"Map x y positions looks Areas Interest.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/add_aois.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map the x and y positions of looks to Areas of Interest. — add_aois","text":"","code":"add_aois(x, aois, default_onscreen = \"tracked\")"},{"path":"http://www.tjmahr.com/littlelisteners/reference/add_aois.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map the x and y positions of looks to Areas of Interest. — add_aois","text":"x dataframe looking data aois AOI list AOIs default_onscreen default label use look onscreen fall AOI. Default \"tracked\"","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/add_aois.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map the x and y positions of looks to Areas of Interest. — add_aois","text":"updated dataframe","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/add_aois.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Map the x and y positions of looks to Areas of Interest. — add_aois","text":"function current assumes conventions used lab. create column called GazeByAOI label AOI look. checking whether columns XMean YMean fall boundaries AOI. Offscreen looks receive NA.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust looking times relative to some event — adjust_times","title":"Adjust looking times relative to some event — adjust_times","text":"function useful critical event occurs trial, like adjust timestamps relative event time.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust looking times relative to some event — adjust_times","text":"","code":"adjust_times(   data,   time_var = quote(Time),   event_var = NULL,   ...,   align = TRUE,   fps = 60,   ties = \"first\" )"},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust looking times relative to some event — adjust_times","text":"data long data frame looking data time_var column data looking times (assumed milliseconds). event_var column data time event ... grouping variables. grouping variables uniquely specify trial eyetracking data. align whether align eyetracking times frame closest event time gets time = 0. fps eyetracking sampling rate. Defaults 60 frames per second. ties break ties smallest times equally close zero. Default \"first\" tie c(-1, 1) aligned c(0, 2).","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust looking times relative to some event — adjust_times","text":"looking data times adjusted event times. default, times aligned frame closest event time gets value 0.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjust looking times relative to some event — adjust_times","text":"","code":"# Consider some raw tims from an eyetrack. For each trial, some critical # event occurs and we have a column with the time of that event for each # trial. trial1 <- data.frame(trial = 1, time_ms = 1:5, event = 2) trial2 <- data.frame(trial = 2, time_ms = 6:10, event = 8.5) trial_times <- dplyr::bind_rows(trial1, trial2) trial_times #>    trial time_ms event #> 1      1       1   2.0 #> 2      1       2   2.0 #> 3      1       3   2.0 #> 4      1       4   2.0 #> 5      1       5   2.0 #> 6      2       6   8.5 #> 7      2       7   8.5 #> 8      2       8   8.5 #> 9      2       9   8.5 #> 10     2      10   8.5  # We want to adjust the times so that time 0 is time of the critical event. adjust_times(trial_times, time_ms, event, trial, fps = 1000) #> # A tibble: 10 × 3 #>    trial time_ms event #>    <dbl>   <dbl> <dbl> #>  1     1      -1   2   #>  2     1       0   2   #>  3     1       1   2   #>  4     1       2   2   #>  5     1       3   2   #>  6     2      -2   8.5 #>  7     2      -1   8.5 #>  8     2       0   8.5 #>  9     2       1   8.5 #> 10     2       2   8.5  # The times are adjusted so that the frame closest to the event time gets # the time zero. Setting `align` to `FALSE` skips this behavior. adjust_times(trial_times, time_ms, event, trial, align = FALSE, fps = 1000) #>    trial time_ms event #> 1      1    -1.0   2.0 #> 2      1     0.0   2.0 #> 3      1     1.0   2.0 #> 4      1     2.0   2.0 #> 5      1     3.0   2.0 #> 6      2    -2.5   8.5 #> 7      2    -1.5   8.5 #> 8      2    -0.5   8.5 #> 9      2     0.5   8.5 #> 10     2     1.5   8.5  # In the second trial there is a tie. Two frames are equally close to 0. By # default the first frame is chosen to be zero, but setting `ties` to # `\"last\"` will break ties with the later frame. adjust_times(trial_times, time_ms, event, trial, ties = \"last\", fps = 1000) #> # A tibble: 10 × 3 #>    trial time_ms event #>    <dbl>   <dbl> <dbl> #>  1     1      -1   2   #>  2     1       0   2   #>  3     1       1   2   #>  4     1       2   2   #>  5     1       3   2   #>  6     2      -3   8.5 #>  7     2      -2   8.5 #>  8     2      -1   8.5 #>  9     2       0   8.5 #> 10     2       1   8.5"},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times_around_zero.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust time values around 0 — adjust_times_around_zero","title":"Adjust time values around 0 — adjust_times_around_zero","text":"Adjust time values around 0","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times_around_zero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust time values around 0 — adjust_times_around_zero","text":"","code":"adjust_times_around_zero(data, time_col = \"Time\", fps = 60, ties = \"first\")"},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times_around_zero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust time values around 0 — adjust_times_around_zero","text":"data dataframe eyetracking data single trial grouped dataframe groups define single trial. time_col name (string) column time value. Defaults \"Time\". fps eyetracking sampling rate. Defaults 60 frames per second. ties break ties smallest times equally close zero. Default \"first\" tie c(-1, 1) aligned c(0, 2).","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/adjust_times_around_zero.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust time values around 0 — adjust_times_around_zero","text":"dataframe updated time values","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/aggregating-looks.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate looks — aggregate_looks","title":"Aggregate looks — aggregate_looks","text":"Aggregate number looks response type grouping variables like Subject, Time, Condition.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/aggregating-looks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate looks — aggregate_looks","text":"","code":"aggregate_looks(data, resp_def, formula)  aggregate_looks2(data, resp_def, resp_var, ...)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/aggregating-looks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate looks — aggregate_looks","text":"data long data frame looking data resp_def response definition list response definition. formula aggregation formula. lefthand terms grouping variables, righthand term column eyetracking responses. resp_var Name column contains eyetracking responses ... Grouping columns.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/aggregating-looks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate looks — aggregate_looks","text":"dataframe grouping columns along number looks response type, proportion (standard error) looks primary response, proportion (standared error) missing data.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/aggregating-looks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregate looks — aggregate_looks","text":"function main tool preparing eyetracking data growth curve analysis. example, aggregation formula like Subject + Time ~ Gaze provide number looks image time subject. aggregate_looks() uses aggregation formula like stats::aggregate(), whereas aggregate_looks2() uses column names.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/aggregating-looks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate looks — aggregate_looks","text":"","code":"target_def <- create_response_def(   label = \"looks to target\",   primary = \"Target\",   others = c(\"PhonologicalFoil\", \"SemanticFoil\", \"Unrelated\"),   elsewhere = \"tracked\",   missing = NA)  four_image_data |>   aggregate_looks(target_def, Subject + TrialNo ~ GazeByImageAOI) #> # A tibble: 24 × 15 #>    .response_def  Subject TrialNo PhonologicalFoil SemanticFoil Target Unrelated #>    <chr>          <chr>     <int>            <int>        <int>  <int>     <int> #>  1 looks to targ… 001P          1              232           80    250       105 #>  2 looks to targ… 001P          2              181           93    242       160 #>  3 looks to targ… 001P          3               79          101    231        66 #>  4 looks to targ… 001P          4              188          135    123       145 #>  5 looks to targ… 001P          5               90          170    164        79 #>  6 looks to targ… 001P          6               70          198    172        24 #>  7 looks to targ… 001P          7               83           47    109       195 #>  8 looks to targ… 001P          8               60           63     77        40 #>  9 looks to targ… 001P          9               71           50     50        50 #> 10 looks to targ… 001P         10               57          305    150        82 #> # ℹ 14 more rows #> # ℹ 8 more variables: Elsewhere <dbl>, Missing <dbl>, Others <dbl>, #> #   Primary <dbl>, Looks <dbl>, Prop <dbl>, PropSE <dbl>, PropNA <dbl>  four_image_data |>   aggregate_looks(target_def, Subject ~ GazeByImageAOI) |>   str() #> tibble [1 × 14] (S3: tbl_df/tbl/data.frame) #>  $ .response_def   : chr \"looks to target\" #>  $ Subject         : chr \"001P\" #>  $ PhonologicalFoil: int 2461 #>  $ SemanticFoil    : int 2478 #>  $ Target          : int 4094 #>  $ Unrelated       : int 2033 #>  $ Elsewhere       : num 1202 #>  $ Missing         : num 8642 #>  $ Others          : num 6972 #>  $ Primary         : num 4094 #>  $ Looks           : num 20910 #>  $ Prop            : num 0.37 #>  $ PropSE          : num 0.00459 #>  $ PropNA          : num 0.413  # With column names four_image_data |>   aggregate_looks2(target_def, GazeByImageAOI, Subject, TrialNo) #> # A tibble: 24 × 15 #>    .response_def  Subject TrialNo PhonologicalFoil SemanticFoil Target Unrelated #>    <chr>          <chr>     <int>            <int>        <int>  <int>     <int> #>  1 looks to targ… 001P          1              232           80    250       105 #>  2 looks to targ… 001P          2              181           93    242       160 #>  3 looks to targ… 001P          3               79          101    231        66 #>  4 looks to targ… 001P          4              188          135    123       145 #>  5 looks to targ… 001P          5               90          170    164        79 #>  6 looks to targ… 001P          6               70          198    172        24 #>  7 looks to targ… 001P          7               83           47    109       195 #>  8 looks to targ… 001P          8               60           63     77        40 #>  9 looks to targ… 001P          9               71           50     50        50 #> 10 looks to targ… 001P         10               57          305    150        82 #> # ℹ 14 more rows #> # ℹ 8 more variables: Elsewhere <dbl>, Missing <dbl>, Others <dbl>, #> #   Primary <dbl>, Looks <dbl>, Prop <dbl>, PropSE <dbl>, PropNA <dbl>  four_image_data |>   aggregate_looks2(target_def, GazeByImageAOI, Subject) |>   str() #> tibble [1 × 14] (S3: tbl_df/tbl/data.frame) #>  $ .response_def   : chr \"looks to target\" #>  $ Subject         : chr \"001P\" #>  $ PhonologicalFoil: int 2461 #>  $ SemanticFoil    : int 2478 #>  $ Target          : int 4094 #>  $ Unrelated       : int 2033 #>  $ Elsewhere       : num 1202 #>  $ Missing         : num 8642 #>  $ Others          : num 6972 #>  $ Primary         : num 4094 #>  $ Looks           : num 20910 #>  $ Prop            : num 0.37 #>  $ PropSE          : num 0.00459 #>  $ PropNA          : num 0.413  phonological_def <- create_response_def(   label = \"looks to phonological foil\",   primary = \"PhonologicalFoil\",   others = c(\"Target\", \"SemanticFoil\", \"Unrelated\"),   elsewhere = \"tracked\",   missing = NA)  # Aggregate looks to multiple response definitions at once defs <- list(target_def, phonological_def) four_image_data |>   aggregate_looks(defs, Subject + BlockNo ~ GazeByImageAOI) |>   dplyr::select(.response_def, Subject, BlockNo, Primary:PropNA) |>   dplyr::mutate(     Prop = round(Prop, 3),     PropSE = round(PropSE, 3),     PropNA = round(PropNA, 3)   ) #> # A tibble: 4 × 8 #>   .response_def              Subject BlockNo Primary Looks  Prop PropSE PropNA #>   <chr>                      <chr>     <int>   <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 looks to target            001P          1    1439 11224 0.357  0.008  0.591 #> 2 looks to target            001P          2    2655  9686 0.377  0.006  0.207 #> 3 looks to phonological foil 001P          1     937 11224 0.233  0.007  0.591 #> 4 looks to phonological foil 001P          2    1524  9686 0.217  0.005  0.207  # Compute a growth curve growth_curve <- four_image_data |>   adjust_times(Time, TargetOnset, Subject, BlockNo, TrialNo) |>   aggregate_looks(target_def, Time ~ GazeByImageAOI) |>   dplyr::filter(-1000 <= Time, Time <= 2000)  library(ggplot2) ggplot(growth_curve) +   aes(x = Time, y = Prop) +   geom_hline(linewidth = 2, color = \"white\", yintercept = .25) +   geom_vline(linewidth = 2, color = \"white\", xintercept = 0) +   geom_pointrange(aes(ymin = Prop - PropSE, ymax = Prop + PropSE)) +   labs(     y = \"Proportion of looks to target\",     x = \"Time relative to target onset [ms]\"    ) +   theme_grey(base_size = 14)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign bins for downsampling looking data — assign_bins","title":"Assign bins for downsampling looking data — assign_bins","text":"Assign bins downsampling looking data","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign bins for downsampling looking data — assign_bins","text":"","code":"assign_bins(   data,   bin_width = 3,   time_var,   ...,   bin_col = \".bin\",   na_location = \"tail\",   partial = FALSE )"},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign bins for downsampling looking data — assign_bins","text":"data dataframe looking data bin_width number items put bin. Default 3. time_var name column representing time ... grouping variables bin_col name column add. Defaults \".bin\". na_location assign NA bin numbers. \"head\" \"tail\" respectively put NA elements head tail vector; \"split\" alternates \"tail\" \"head\". partial whether exclude values fit evenly bins. Defaults FALSE, user warned bin incomplete.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign bins for downsampling looking data — assign_bins","text":"original dataframe added column bin numbers. dataframe sorted grouping time variables.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign bin numbers to a vector — assign_bins_vec","title":"Assign bin numbers to a vector — assign_bins_vec","text":"first step binning/-sampling data assigning items bins. function takes vector bin size returns bin assignments.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign bin numbers to a vector — assign_bins_vec","text":"","code":"assign_bins_vec(xs, bin_width = 3, na_location = \"tail\", partial = FALSE)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins_vec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign bin numbers to a vector — assign_bins_vec","text":"xs vector bin_width number items put bin. Default 3. na_location assign NA bin numbers. \"head\" \"tail\" respectively put NA elements head tail vector; \"split\" alternates \"tail\" \"head\". partial whether exclude values fit evenly bins. Defaults FALSE, user warned bin incomplete.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins_vec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign bin numbers to a vector — assign_bins_vec","text":"vector bin-numbers. bin_width evenly divide xs, remainder elements given bin number NA.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/assign_bins_vec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign bin numbers to a vector — assign_bins_vec","text":"","code":"if (FALSE) { # \\dontrun{ assign_bins_vec(1:14, bin_width = 3, \"head\") # [1] NA NA  1  1  1  2  2  2  3  3  3  4  4  4 assign_bins_vec(1:14, bin_width = 3, \"tail\") # [1]  1  1  1  2  2  2  3  3  3  4  4  4 NA NA assign_bins_vec(1:7, bin_width = 5, \"split\") # [1] NA  1  1  1  1  1 NA assign_bins_vec(1:8, bin_width = 5, \"split\") # [1] NA  1  1  1  1  1 NA NA } # }"},{"path":"http://www.tjmahr.com/littlelisteners/reference/convert_datawiz_code_to_aoi.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to DataWiz codes to AOI names — convert_datawiz_code_to_aoi","title":"Convert to DataWiz codes to AOI names — convert_datawiz_code_to_aoi","text":"Convert DataWiz codes AOI names","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/convert_datawiz_code_to_aoi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to DataWiz codes to AOI names — convert_datawiz_code_to_aoi","text":"","code":"convert_datawiz_code_to_aoi(xs)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/convert_datawiz_code_to_aoi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to DataWiz codes to AOI names — convert_datawiz_code_to_aoi","text":"xs vector DataWiz codes (-, ., 0, 1)","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/convert_datawiz_code_to_aoi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to DataWiz codes to AOI names — convert_datawiz_code_to_aoi","text":"vector NA \"-\", \"Target\" \"1\", \"Distractor\" \"0\", \"tracked\" \".\".","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/create_aoi.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an AOI object — create_aoi","title":"Create an AOI object — create_aoi","text":"Create object representing Area Interest (AOI). rectangles supported (like jpeg image experiment). Pixel (0,0) lower left corner screen.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/create_aoi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an AOI object — create_aoi","text":"","code":"create_aoi(aoi_name, x_pix, y_pix, screen_width = 1920, screen_height = 1080)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/create_aoi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an AOI object — create_aoi","text":"aoi_name label AOI x_pix location left right edges pixels. y_pix location bottom top edges pixels. screen_width width screen pixels. Defaults 1920. screen_height width screen pixels. Defaults 1080.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/create_aoi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an AOI object — create_aoi","text":"AOI object.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/cycle_response_def.html","id":null,"dir":"Reference","previous_headings":"","what":"Create complementary response definitions — cycle_response_def","title":"Create complementary response definitions — cycle_response_def","text":"typical response definition, primary response compared competitors. Oftentimes, interested also comparing competitors images. function quickly assembles full cycle response definitions.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/cycle_response_def.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create complementary response definitions — cycle_response_def","text":"","code":"cycle_response_def(response_def)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/cycle_response_def.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create complementary response definitions — cycle_response_def","text":"response_def response definition use template definitions.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/cycle_response_def.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create complementary response definitions — cycle_response_def","text":"list response definitions member c(response_def$primary, response_def$others) used primary response.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/cycle_response_def.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create complementary response definitions — cycle_response_def","text":"","code":"# Create one definition def <- create_response_def(   primary = 1,   others = c(5, 8, 9),   elsewhere = 0,   missing = NA )  # Create the full cycle of response definitions cycle_response_def(def) #> [[1]] #> List of 5 #>  $ response_def: chr \"1\" #>  $ primary     : num 1 #>  $ others      : num [1:3] 5 8 9 #>  $ elsewhere   : num 0 #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\" #>  #> [[2]] #> List of 5 #>  $ response_def: chr \"5\" #>  $ primary     : num 5 #>  $ others      : num [1:3] 1 8 9 #>  $ elsewhere   : num 0 #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\" #>  #> [[3]] #> List of 5 #>  $ response_def: chr \"8\" #>  $ primary     : num 8 #>  $ others      : num [1:3] 1 5 9 #>  $ elsewhere   : num 0 #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\" #>  #> [[4]] #> List of 5 #>  $ response_def: chr \"9\" #>  $ primary     : num 9 #>  $ others      : num [1:3] 1 5 8 #>  $ elsewhere   : num 0 #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\" #>"},{"path":"http://www.tjmahr.com/littlelisteners/reference/empirical_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute empirical logit — empirical_logit","title":"Compute empirical logit — empirical_logit","text":"Compute empirical logit","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/empirical_logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute empirical logit — empirical_logit","text":"","code":"empirical_logit(x, y)  empirical_logit_weight(x, y)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/empirical_logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute empirical logit — empirical_logit","text":"x vector containing number looks target y vector containing number looks distractors","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/empirical_logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute empirical logit — empirical_logit","text":"empirical_logit returns empirical logit looking target. empirical_logit_weight returns weights values.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/empirical_logit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute empirical logit — empirical_logit","text":"Dale Barr's Walkthrough \"empirical logit\" analysis R","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/example_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Locate the path of example eyetracking files — example_files","title":"Locate the path of example eyetracking files — example_files","text":"Locate path example eyetracking files","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/example_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Locate the path of example eyetracking files — example_files","text":"","code":"example_files(which = 1)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/example_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Locate the path of example eyetracking files — example_files","text":"index batch example files load","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/example_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Locate the path of example eyetracking files — example_files","text":"Paths banch examples files bundled littlelisteners package.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/example_files.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Locate the path of example eyetracking files — example_files","text":"function wrapper system.file()  locate paths bundled eyetracking data. files used test demonstrate functionality package. following sets files included: Coartic_Block1_001P00XS1 - Data block trials eyetracking performed Tobii Eyetracker Eprime experiment. Coartic_Block2_001P00XS1 - Data second block trials experiment.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/find_frequent_interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the most frequent interval of values — find_frequent_interval","title":"Find the most frequent interval of values — find_frequent_interval","text":"trials varying lengths, can helpful find interval time shared trials.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/find_frequent_interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the most frequent interval of values — find_frequent_interval","text":"","code":"find_frequent_interval(xs, min_freq = 0.8)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/find_frequent_interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the most frequent interval of values — find_frequent_interval","text":"xs set values (times) min_freq minimum frequency times keep","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/find_frequent_interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the most frequent interval of values — find_frequent_interval","text":"list minimum maximum values frequency least 80%.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/find_frequent_interval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the most frequent interval of values — find_frequent_interval","text":"","code":"times <- c(   -5:10, -10:10, -8:10, -8:10, -8:11, -8:13, -8:4,   -5:12, -10:9 ) find_frequent_interval(times) #> $lower #> [1] -5 #>  #> $upper #> [1] 9 #>"},{"path":"http://www.tjmahr.com/littlelisteners/reference/four_image_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Example data from a Visual World experiment — four_image_data","title":"Example data from a Visual World experiment — four_image_data","text":"Example data Visual World experiment","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/four_image_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example data from a Visual World experiment — four_image_data","text":"","code":"four_image_data"},{"path":"http://www.tjmahr.com/littlelisteners/reference/four_image_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example data from a Visual World experiment — four_image_data","text":"data frame 20,910 rows 25 variables","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/interpolate_looks.html","id":null,"dir":"Reference","previous_headings":"","what":"AOI-based gaze interpolation — interpolate_looks","title":"AOI-based gaze interpolation — interpolate_looks","text":"Fills windows missing data AOI fixated beginning end missing data window. example, sequence \"Target\", NA, NA, \"Target\" interpolated \"Target\", \"Target\", \"Target\", \"Target\".","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/interpolate_looks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AOI-based gaze interpolation — interpolate_looks","text":"","code":"interpolate_looks(   x,   window,   fps,   response_col,   interp_col,   fillable,   missing_looks )"},{"path":"http://www.tjmahr.com/littlelisteners/reference/interpolate_looks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AOI-based gaze interpolation — interpolate_looks","text":"x dataframe grouped eyetracking data. row single frame eyetracking. Use dplyr::group_by() set grouping columns data. groups specify single trial eyetracking data. window maximum amount missing data (milliseconds) can interpolated. spans missing data less equal duration interpolated fps number eyetracking frames (dataframe rows) per second response_col (character) name column eyetracking response data interp_col (character) name column add dataframe. column records whether frame interpolated (TRUE) (FALSE) fillable values response column interpolation legal. typically AOI locations. missing_looks values can imputed.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/interpolate_looks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AOI-based gaze interpolation — interpolate_looks","text":"Use window constrain duration missing data windows can filled. conventionally use 150ms expect someone shift gaze Image Image B Image amount time.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/interpolate_looks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"AOI-based gaze interpolation — interpolate_looks","text":"","code":"# We have time in ms, measured at 60 fps, and # we want to fill in gaps of 100 ms. looks <- tibble::tribble(   ~Subject, ~Trial, ~Time,    ~AOI,         ~Hint,        \"A\",      1,  1000,  \"Left\",     \"present\",        \"A\",      1,  1017,  \"Left\",     \"present\",        \"A\",      1,  1034,      NA,   \"legal gap\",        \"A\",      1,  1051,      NA,   \"legal gap\",        \"A\",      1,  1068,      NA,   \"legal gap\",        \"A\",      1,  1084,  \"Left\",     \"present\",        \"A\",      1,  1100,      NA, \"illegal gap\",        \"A\",      2,   983,  \"Left\",     \"present\",        \"A\",      2,  1000, \"Right\",     \"present\",        \"A\",      2,  1017,      NA, \"illegal gap\",        \"A\",      2,  1034,      NA, \"illegal gap\",        \"A\",      2,  1051,      NA, \"illegal gap\",        \"A\",      2,  1068,      NA, \"illegal gap\",        \"A\",      2,  1084,      NA, \"illegal gap\",        \"A\",      2,  1100,      NA, \"illegal gap\",        \"A\",      2,  1118,      NA, \"illegal gap\",        \"A\",      2,  1135, \"Right\",     \"present\", )  # Note that only the \"legal gap\" rows were interpolated looks |>   dplyr::group_by(Trial) |>   interpolate_looks(     window = 100,     fps = 60,     response_col = \"AOI\",     interp_col = \"Interpolated\",     fillable = c(\"Left\", \"Right\"),     missing_looks = NA   ) #> # A tibble: 17 × 6 #> # Groups:   Trial [2] #>    Subject Trial  Time AOI   Hint        Interpolated #>    <chr>   <dbl> <dbl> <chr> <chr>       <lgl>        #>  1 A           1  1000 Left  present     FALSE        #>  2 A           1  1017 Left  present     FALSE        #>  3 A           1  1034 Left  legal gap   TRUE         #>  4 A           1  1051 Left  legal gap   TRUE         #>  5 A           1  1068 Left  legal gap   TRUE         #>  6 A           1  1084 Left  present     FALSE        #>  7 A           1  1100 NA    illegal gap FALSE        #>  8 A           2   983 Left  present     FALSE        #>  9 A           2  1000 Right present     FALSE        #> 10 A           2  1017 NA    illegal gap FALSE        #> 11 A           2  1034 NA    illegal gap FALSE        #> 12 A           2  1051 NA    illegal gap FALSE        #> 13 A           2  1068 NA    illegal gap FALSE        #> 14 A           2  1084 NA    illegal gap FALSE        #> 15 A           2  1100 NA    illegal gap FALSE        #> 16 A           2  1118 NA    illegal gap FALSE        #> 17 A           2  1135 Right present     FALSE"},{"path":"http://www.tjmahr.com/littlelisteners/reference/littlelisteners.html","id":null,"dir":"Reference","previous_headings":"","what":"littlelisteners. — littlelisteners","title":"littlelisteners. — littlelisteners","text":"package houses frequently used functions working hand-coded eyetracking data.","code":""},{"path":[]},{"path":"http://www.tjmahr.com/littlelisteners/reference/littlelisteners.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"littlelisteners. — littlelisteners","text":"Maintainer: Tristan Mahr tristan.mahr@wisc.edu (ORCID)","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/melt_datawiz.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert DataWiz data into long format — melt_datawiz","title":"Convert DataWiz data into long format — melt_datawiz","text":"DataWiz files several columns F0, F33, F67, etc. time sample. function converts dataframe file long format, single time column single column gaze responses.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/melt_datawiz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert DataWiz data into long format — melt_datawiz","text":"","code":"melt_datawiz(df, key_col = \"Time\", value_col = \"Look\")"},{"path":"http://www.tjmahr.com/littlelisteners/reference/melt_datawiz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert DataWiz data into long format — melt_datawiz","text":"df dataframe created reading datawiz file key_col name new column holds time values value_col name new column holds looking data time sample","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/melt_datawiz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert DataWiz data into long format — melt_datawiz","text":"long data-frame","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_datawiz.html","id":null,"dir":"Reference","previous_headings":"","what":"Read eyetracking data from a datawiz file — read_datawiz","title":"Read eyetracking data from a datawiz file — read_datawiz","text":"Read eyetracking data datawiz file","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_datawiz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read eyetracking data from a datawiz file — read_datawiz","text":"","code":"read_datawiz(filename, sampling_rate = 33.3333)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_datawiz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read eyetracking data from a datawiz file — read_datawiz","text":"filename txt file generated datawiz sampling_rate rate video recording ms. default, value 33.3 1 frame every 33.3 ms.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_datawiz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read eyetracking data from a datawiz file — read_datawiz","text":"dataframe containing cleaned-eyetracking data","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_datawiz.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read eyetracking data from a datawiz file — read_datawiz","text":"files exported DataWiz series tab-separated data files combined single file. means header row (column names separated tabs) repeated throughout file. repeated header rows removed. header rows indicate time eyetracking samples columns named \"F0\", \"F33\", \"F67\", etc. also columns blank names column \"F0\". also looking samples \"F0\". function back-fills column names first column \"F0\" changes \" \" \"X33\", X indicates negative time sample.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_gazedata.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a .gazedata file for an experiment — read_gazedata","title":"Load a .gazedata file for an experiment — read_gazedata","text":"Loads .gazedata file created Eprime experiment running Tobii eyetracker, performs typical data reduction file.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_gazedata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a .gazedata file for an experiment — read_gazedata","text":"","code":"read_gazedata(   gazedata_path,   eyes = \"both\",   means_need_both = FALSE,   apply_corrections = TRUE )"},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_gazedata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a .gazedata file for an experiment — read_gazedata","text":"gazedata_path path .gazedata file parsed. eyes string describing eye(s) selected Mean columns. Valid options \"\", \"left\", \"right\". Defaults \"\". \"left\" selected, left eye used calculate XMean, YMean, etc. columns. means_need_both logical value indicating eyes required compute Mean columns. Defaults FALSE. FALSE, NA values ignored, example, XMean computed XLeft .25 XRight NA. apply_corrections whether low-level adjustments like coding offscreen looks NA, negative pupil diameters NA, negative distances NA, flip y-axis origin lower-left corner. Defaults TRUE. used FALSE case \"raw\" data needed.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_gazedata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a .gazedata file for an experiment — read_gazedata","text":"dataframe containing parsed gazedata. row dataframe   contains eye-tracking data single frame time recorded   experiment.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_gazedata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load a .gazedata file for an experiment — read_gazedata","text":"extract columns following columns: TrialId, RTTime, XGazePosLeftEye, XGazePosRightEye, YGazePosLeftEye, YGazePosRightEye, DistanceLeftEye, DistanceRightEye, DiameterPupilLeftEye DiameterPupilRightEye. column values loaded, make three modifications gazedata (apply_corrections TRUE). Gaze measurements Validity codes greater equal   1 replaced NA values. X,Y gaze values defined screen proportions. Values fall   outside [0,1] outside boundaries screen therefore   nonsensical. Replace NA. perform similar correction   pupil diameters eye-distances replacing negative   values NA. origin screen upper-left-hand corner screen.   Flip y-values origin familiar position   lower-left-hand corner screen. way, low y values closer   bottom screen. Compute mean x, y, distance diameter values left   right eyes. NA values ignored computing mean,   pair (XLeft = NA, XRight = .5) yields XMean = .5.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_gazedata.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Load a .gazedata file for an experiment — read_gazedata","text":"Tobii Toolbox Matlab: Product   Description & User Guide","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/read_gazedata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a .gazedata file for an experiment — read_gazedata","text":"","code":"gazedata_path <- example_files(1)[1] read_gazedata(gazedata_path) #> # A tibble: 12,573 × 17 #>    Basename TrialNo TobiiTime  Time Origin XLeft XRight XMean YLeft YRight YMean #>    <chr>      <int>     <dbl> <int> <chr>  <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> #>  1 Coartic…       1   1.36e12 37312 Lower… 0.355  0.367 0.361 0.561  0.551 0.556 #>  2 Coartic…       1   1.36e12 37329 Lower… 0.352  0.372 0.362 0.559  0.562 0.561 #>  3 Coartic…       1   1.36e12 37345 Lower… 0.359  0.366 0.362 0.564  0.566 0.565 #>  4 Coartic…       1   1.36e12 37362 Lower… 0.353  0.366 0.360 0.565  0.573 0.569 #>  5 Coartic…       1   1.36e12 37378 Lower… 0.350  0.367 0.359 0.558  0.579 0.568 #>  6 Coartic…       1   1.36e12 37395 Lower… 0.352  0.363 0.358 0.559  0.574 0.567 #>  7 Coartic…       1   1.36e12 37412 Lower… 0.357  0.360 0.358 0.566  0.565 0.565 #>  8 Coartic…       1   1.36e12 37428 Lower… 0.352  0.367 0.359 0.563  0.559 0.561 #>  9 Coartic…       1   1.36e12 37445 Lower… 0.348  0.374 0.361 0.554  0.558 0.556 #> 10 Coartic…       1   1.36e12 37461 Lower… 0.351  0.364 0.357 0.569  0.565 0.567 #> # ℹ 12,563 more rows #> # ℹ 6 more variables: ZLeft <dbl>, ZRight <dbl>, ZMean <dbl>, #> #   DiameterLeft <dbl>, DiameterRight <dbl>, DiameterMean <dbl>"},{"path":"http://www.tjmahr.com/littlelisteners/reference/response-definition.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a response definition — create_response_def","title":"Create a response definition — create_response_def","text":"response definition controls aggregate_looks() works.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/response-definition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a response definition — create_response_def","text":"","code":"create_response_def(   primary,   others,   elsewhere = NULL,   missing = NA,   label = NULL )"},{"path":"http://www.tjmahr.com/littlelisteners/reference/response-definition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a response definition — create_response_def","text":"primary primary response interest others responses interest elsewhere responses ignore missing responses indicate missing data. Defaults NA. label optional label response definition. Defaults value primary.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/response-definition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a response definition — create_response_def","text":"response_def object","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/response-definition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a response definition — create_response_def","text":"deal eyetracking data generic way, need way describe eyetracking responses. assume four basic gaze types. Primary responses: gaze primary target image. responses: Gazes competing images. Elsewhere looks: gaze onscreen primary response. Typically, occurs participant shifting images. Missing looks: missing offscreen gaze. response definition programmatic way describing response types, allows aggregate_looks() map gaze data onto looking counts.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/response-definition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a response definition — create_response_def","text":"","code":"create_response_def(   label = \"looks to target\",   primary = \"Target\",   others = c(\"PhonologicalFoil\", \"SemanticFoil\", \"Unrelated\"),   elsewhere = \"tracked\",   missing = NA) #> List of 5 #>  $ response_def: chr \"looks to target\" #>  $ primary     : chr \"Target\" #>  $ others      : chr [1:3] \"PhonologicalFoil\" \"SemanticFoil\" \"Unrelated\" #>  $ elsewhere   : chr \"tracked\" #>  $ missing     : logi NA #>  - attr(*, \"class\")= chr \"response_def\""},{"path":"http://www.tjmahr.com/littlelisteners/reference/se_prop.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard error for proportions — se_prop","title":"Standard error for proportions — se_prop","text":"See http://www.r-tutor.com/elementary-statistics/interval-estimation/interval-estimate-population-proportion","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/se_prop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard error for proportions — se_prop","text":"","code":"se_prop(proportion, n_possible)"},{"path":"http://www.tjmahr.com/littlelisteners/reference/se_prop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard error for proportions — se_prop","text":"proportion proportions hits n_possible numbers total events","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/se_prop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard error for proportions — se_prop","text":"standard errors proportion estimates","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/trim_to_bin_width.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncate times to fit bin width — trim_to_bin_width","title":"Truncate times to fit bin width — trim_to_bin_width","text":"Samples eyetracking data excluded number frames evenly divisible given bin width. example, given bin width 3 frames, trial 181 frames lose 1 frame. frames aligned key time value specific position bin. example, setting time 0 position 1 truncate times time 0 first frame inside bin.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/trim_to_bin_width.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncate times to fit bin width — trim_to_bin_width","text":"","code":"trim_to_bin_width(   data,   bin_width = 3,   key_time = NULL,   key_position = 1,   time_var,   ...,   min_time = NULL,   max_time = NULL )"},{"path":"http://www.tjmahr.com/littlelisteners/reference/trim_to_bin_width.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncate times to fit bin width — trim_to_bin_width","text":"data dataframe looking data bin_width number items put bin. Default 3. key_time, key_position arguments controlling trimming. given time value (key_time) specific position within bin (key_position). example, given value 0 position 2, trimming force frame time 0 fall second frame bin. time_var name column representing time ... grouping variables min_time, max_time optional arguments controlling trimming. used, time values filtered exclude whole bins frames min_time max_time.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/trim_to_bin_width.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncate times to fit bin width — trim_to_bin_width","text":"original dataframe time column trimmed make easier bin time values groups bin_width.","code":""},{"path":"http://www.tjmahr.com/littlelisteners/reference/trim_to_bin_width.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncate times to fit bin width — trim_to_bin_width","text":"","code":"data1 <- tibble::tibble(   task = \"testing\",   id = \"test1\",   time = -4:6,   frame = seq_along(time) )  data2 <- tibble::tibble(   task = \"testing\",   id = \"test2\",   time = -5:5,   frame = seq_along(time) )  # Number of rows per id is divisible by bin width # and time 0 is center of its bin dplyr::bind_rows(data1, data2) |>   trim_to_bin_width(3, key_time = 0, key_position = 2, time, id) |>   assign_bins(3, time, id) |>   dplyr::group_by(id, .bin) |>   dplyr::mutate(center_time = median(time)) #> # A tibble: 18 × 6 #> # Groups:   id, .bin [6] #>    task    id     time frame  .bin center_time #>    <chr>   <chr> <int> <int> <int>       <int> #>  1 testing test1    -4     1     1          -3 #>  2 testing test1    -3     2     1          -3 #>  3 testing test1    -2     3     1          -3 #>  4 testing test1    -1     4     2           0 #>  5 testing test1     0     5     2           0 #>  6 testing test1     1     6     2           0 #>  7 testing test1     2     7     3           3 #>  8 testing test1     3     8     3           3 #>  9 testing test1     4     9     3           3 #> 10 testing test2    -4     2     1          -3 #> 11 testing test2    -3     3     1          -3 #> 12 testing test2    -2     4     1          -3 #> 13 testing test2    -1     5     2           0 #> 14 testing test2     0     6     2           0 #> 15 testing test2     1     7     2           0 #> 16 testing test2     2     8     3           3 #> 17 testing test2     3     9     3           3 #> 18 testing test2     4    10     3           3  # And exclude times in bins before some minimum time dplyr::bind_rows(data1, data2) |>   trim_to_bin_width(     bin_width = 3,     key_time = 0,     key_position = 2,     time,     id,     min_time = -1 ) |>   assign_bins(3, time, id) #> # A tibble: 12 × 5 #>    task    id     time frame  .bin #>    <chr>   <chr> <int> <int> <int> #>  1 testing test1    -1     4     1 #>  2 testing test1     0     5     1 #>  3 testing test1     1     6     1 #>  4 testing test1     2     7     2 #>  5 testing test1     3     8     2 #>  6 testing test1     4     9     2 #>  7 testing test2    -1     5     1 #>  8 testing test2     0     6     1 #>  9 testing test2     1     7     1 #> 10 testing test2     2     8     2 #> 11 testing test2     3     9     2 #> 12 testing test2     4    10     2  # And exclude times in bins after some maximum time dplyr::bind_rows(data1, data2) |>   trim_to_bin_width(     bin_width = 3,     key_time = 0,     key_position = 2,     time, id,     min_time = -1,     max_time = 4   ) |>   assign_bins(3, time, id) #> # A tibble: 12 × 5 #>    task    id     time frame  .bin #>    <chr>   <chr> <int> <int> <int> #>  1 testing test1    -1     4     1 #>  2 testing test1     0     5     1 #>  3 testing test1     1     6     1 #>  4 testing test1     2     7     2 #>  5 testing test1     3     8     2 #>  6 testing test1     4     9     2 #>  7 testing test2    -1     5     1 #>  8 testing test2     0     6     1 #>  9 testing test2     1     7     1 #> 10 testing test2     2     8     2 #> 11 testing test2     3     9     2 #> 12 testing test2     4    10     2"}]
